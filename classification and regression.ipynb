{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment 1_Submitted.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"TcQQvxZwa2GQ","colab_type":"code","colab":{}},"source":["# 1.1 Data loading for classification: Using torchvision.datasets for MNIST (Done)\n","import torch\n","import torchvision\n","from torchvision import transforms, utils\n","import torchvision.datasets as datasets\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","\n","train_set = datasets.MNIST('.', download=True, train=True, transform=transforms.ToTensor())\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","\n","\n","figure = plt.figure()\n","num_of_images = 10\n","\n","for index in range(1, num_of_images+1):\n","  plt.subplot(1, 10, index)\n","  plt.axis('off')\n","  plt.imshow(images[index].numpy().squeeze(), cmap='gray')\n","  plt.title(\"{}\".format(labels[index]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MR9iamAWbHlc","colab_type":"code","colab":{}},"source":["# 1.1 Data loading for classification: Using torchvision.datasets for FashionMNIST (Done)\n","import torch\n","import torchvision\n","from torchvision import transforms, utils\n","import torchvision.datasets as datasets\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","\n","train_set = datasets.FashionMNIST('.', download=True, train=True, transform=transforms.ToTensor())\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n","\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","\n","num_of_images = 10\n","for index in range(1, num_of_images + 1):\n","    ax = plt.subplot(1, 10, index)\n","    ax.axis('off')\n","    ax.imshow(images[index,:,:,:].squeeze(), cmap='gray') # images.shape is torch.size([64,1,28,28]). squeeze() is needed for making (1,28,28) to (28,28) image.\n","    plt.title(\"{}\".format(labels[index]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-NOOuMJHbMmF","colab_type":"code","colab":{}},"source":["# 1.1 Data loading for classification: Using Custom DataLoader for MNIST (Done)\n","import torch\n","import torchvision\n","from torchvision import transforms, utils\n","import torchvision.datasets as datasets\n","from torch.utils.data import Dataset, DataLoader\n","import scipy.io as sio\n","from os.path import dirname, normpath, normcase, join as pjoin\n","import numpy as np\n","import urllib.request\n","from skimage import io\n","import gzip\n","import pickle\n","import matplotlib.cm as cm\n","import matplotlib.pyplot as plt\n","from torchvision.transforms import ToTensor\n","\n","class CustomMNIST(Dataset):\n","  \n","  def __init__(self, mnist, root_dir):\n","    \n","    with gzip.open(mnist, 'rb') as f:\n","      self.train_set, self.valid_set, self.test_set = pickle.load(f, encoding='bytes')\n","      \n","    self.root_dir = root_dir\n","    train_x, train_y = self.train_set\n","    self.len = train_x.shape[0]\n","    self.x_data = torch.from_numpy(train_x[:,:])\n","    self.y_data = torch.from_numpy(train_y)\n","\n","  def __getitem__(self, index):\n","    return self.x_data[index].reshape((28,28)), self.y_data[index]\n","  \n","  def __len__(self):\n","    return self.len\n","    \n","url_pkl= 'https://github.com/mnielsen/neural-networks-and-deep-learning/raw/ddf26dcfa085cdccd076b7d222cce1482338eb64/data/mnist.pkl.gz'\n","urllib.request.urlretrieve(url_pkl, '/content/drive/My Drive/mnist.pkl.gz')\n","mnist = pjoin('/content/drive/My Drive/mnist.pkl.gz') # mnist pickle file path\n","train_set = CustomMNIST(mnist, root_dir='/content/drive/My Drive/')\n","train_loader = DataLoader(train_set, batch_size=10, shuffle=True, num_workers=2)\n","\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","\n","for i in range(len(labels)):\n","  image = images[i,:,:]\n","  label = labels[i]\n","\n","  print(i, images[i,:,:].shape, labels.shape)\n","\n","  ax = plt.subplot(1, 4, i + 1)\n","  plt.tight_layout()\n","  ax.set_title('Sample #{}'.format(i))\n","  ax.axis('off')\n","  plt.imshow(images[i,:,:], cmap=cm.Greys_r)  \n","  plt.title(\"{}\".format(labels[i]))\n","  \n","  if i == 3:\n","    plt.show()\n","    break"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDgVipNhbVdy","colab_type":"code","colab":{}},"source":["# 1.2 Data loading for regression: Using custom dataset for LSP (Done)\n","# Visualization without resizing images\n","import torch\n","import torchvision\n","from torchvision import transforms, utils\n","import torchvision.datasets as datasets\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","import scipy.io as sio\n","from os.path import dirname, normpath, normcase, join as pjoin\n","import numpy as np\n","import urllib.request\n","from skimage import io\n","import os\n","\n","class CustomLSP(Dataset):\n","  \n","  def __init__(self, data_dir, root_dir):\n","    joints_dir = pjoin(data_dir, 'joints.mat')\n","    self.images_folder = pjoin(data_dir, 'images')\n","    #visualized_folder = pjoin(data_dir, 'visualized')\n","    mat_contents = sio.loadmat(joints_dir)\n","    self.joints = mat_contents['joints']\n","    self.images = sorted(os.listdir(self.images_folder)) # sorted list of images\n","      \n","  def __getitem__(self, index):\n","    im = pjoin(self.images_folder, self.images[index])\n","    im = plt.imread(im) # numpy array of the image\n","    joints = self.joints[:,:,index]\n","    return im, joints\n","  \n","  def __len__(self):\n","    self.len = print(im.shape)\n","    return self.len\n","\n","data_dir = pjoin('/content/drive/My Drive/lsp_dataset')\n","data = CustomLSP(data_dir, root_dir='/content/drive/My Drive/')\n","\n","################### Visualization ############################\n","num_of_images = 3\n","for index in range(0, num_of_images):\n","  images, joints = data[index]\n","  print('sample #{} has shape {}'.format(index, images.shape))\n","  f = plt.figure(figsize=(8,8))\n","  ax = f.add_subplot(1, num_of_images, index+1)\n","  ax.axis('off')\n","  ax.imshow(images)\n","  ax.plot([joints[0,0],joints[0,1],joints[0,2]],[joints[1,0],joints[1,1],joints[1,2]],marker = 'o', c='r', zorder=1)\n","  ax.plot([joints[0,3],joints[0,4],joints[0,5]],[joints[1,3],joints[1,4],joints[1,5]],marker = 'o', c='r', zorder=1)\n","  ax.plot([joints[0,6],joints[0,7],joints[0,8]],[joints[1,6],joints[1,7],joints[1,8]],marker = 'o', c='r', zorder=1)\n","  ax.plot([joints[0,9],joints[0,10],joints[0,11]],[joints[1,9],joints[1,10],joints[1,11]],marker = 'o', c='r', zorder=1)\n","  ax.plot([joints[0,12],joints[0,13]],[joints[1,12],joints[1,13]],marker = 'o', c='r', zorder=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MIESFltBbeN6","colab_type":"code","colab":{}},"source":["# 1.2 Data loading for regression: Using custom dataset for LSP with variable batch size dataloader and splitting dataset to train and test sets (Done)\n","# Visualization after resizing images\n","import torch\n","import torchvision\n","from torchvision import transforms, utils\n","import torchvision.datasets as datasets\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","import scipy.io as sio\n","from os.path import dirname, normpath, normcase, join as pjoin\n","import numpy as np\n","import urllib.request\n","from skimage import io\n","import os\n","import math\n","import cv2\n","\n","Batch_size = 3; # samples in one batch\n","train_size = 80; # 80% of the data\n","test_size = 100 - train_size; # 20% of the data \n","\n","class CustomLSP(Dataset):\n","  \n","  def __init__(self, data_dir, train_size, train):\n","    joints_dir = pjoin(data_dir, 'joints.mat')\n","    images_folder = pjoin(data_dir, 'images')\n","    #visualized_folder = pjoin(data_dir, 'visualized')\n","    mat_contents = sio.loadmat(joints_dir)\n","    joints = mat_contents['joints']\n","    images = sorted(os.listdir(images_folder)) # sorted list of images\n","    self.train = train\n","\n","    if self.train == True:\n","      self.train_len = train_size * len(images) / 100 # this is train_size * 2000 / 100\n","      self.train_image_set = []\n","      self.train_joint_set = []\n","      for i in range(0,int(self.train_len)):\n","        \n","        # resizing images to equal sizes and modifying joints accordingly\n","        im = plt.imread(pjoin(images_folder,images[i]))\n","        h, w = im.shape[:2]\n","        im = cv2.resize(im, (256, 256)) \n","        im = torch.from_numpy(im)\n","        self.train_image_set.append(im)\n","        joints_i = torch.from_numpy(joints[:2,:,i]) # ignoring the visibility term in joints\n","        joints_i[0,:] = torch.mul(joints_i[0,:], 256/w) # modifying joints\n","        joints_i[1,:] = torch.mul(joints_i[1,:], 256/h) # modifying joints\n","        self.train_joint_set.append(joints_i)\n","        \n","    if self.train == False:\n","      self.train_len = train_size * len(images) / 100 # this is train_size * 2000 / 100\n","      self.test_len = (100 - train_size) * len(images) / 100\n","      self.test_image_set = []\n","      self.test_joint_set = []\n","      for i in range(int(self.train_len),len(images)):\n","\n","        # resizing images to equal sizes and modifying joints accordingly\n","        im = plt.imread(pjoin(images_folder,images[i]))\n","        h , w = im.shape[:2]\n","        im = cv2.resize(im, (256, 256)) \n","        im = torch.from_numpy(im)\n","        self.test_image_set.append(im)\n","        joints_i = torch.from_numpy(joints[:2,:,i]) # ignoring the visibility term in joints\n","        joints_i[0,:] = torch.mul(joints_i[0,:], 256/w) # modifying joints\n","        joints_i[1,:] = torch.mul(joints_i[1,:], 256/h) # modifying joints\n","        self.test_joint_set.append(joints_i)\n","\n","  def __getitem__(self, index):\n","    if self.train == True:\n","      train_images = self.train_image_set[index]\n","      train_joints = self.train_joint_set[index]\n","      return train_images, train_joints\n","    if self.train == False:\n","      test_images = self.test_image_set[index]\n","      test_joints = self.test_joint_set[index]\n","      return test_images, test_joints\n","  \n","  def __len__(self):\n","    if self.train == True:\n","      return int(self.train_len)\n","    if self.train == False:\n","      return int(self.test_len)\n","\n","data_dir = pjoin('/content/drive/My Drive/lsp_dataset')\n","train_set = CustomLSP(data_dir, train_size=80, train=True)\n","test_set = CustomLSP(data_dir, train_size=80, train=False)\n","train_loader = torch.utils.data.DataLoader(train_set, Batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_set, Batch_size, shuffle=True)\n","dataiter = iter(train_loader)\n","train_images, train_joints = dataiter.next()\n","################### Visualization ############################\n","num_of_images = Batch_size\n","for index in range(0, num_of_images):\n","  image = train_images[index]\n","  joints = train_joints[index]\n","  print('sample #{} has shape {}'.format(index, image.shape))\n","  f = plt.figure(figsize=(10,10))\n","  ax = f.add_subplot(1, num_of_images, index+1)\n","  ax.axis('off')\n","  ax.imshow(image)\n","  ax.plot([joints[0,0],joints[0,1],joints[0,2]],[joints[1,0],joints[1,1],joints[1,2]],marker = 'o', c='r', zorder=1)\n","  ax.plot([joints[0,3],joints[0,4],joints[0,5]],[joints[1,3],joints[1,4],joints[1,5]],marker = 'o', c='r', zorder=1)\n","  ax.plot([joints[0,6],joints[0,7],joints[0,8]],[joints[1,6],joints[1,7],joints[1,8]],marker = 'o', c='r', zorder=1)\n","  ax.plot([joints[0,9],joints[0,10],joints[0,11]],[joints[1,9],joints[1,10],joints[1,11]],marker = 'o', c='r', zorder=1)\n","  ax.plot([joints[0,12],joints[0,13]],[joints[1,12],joints[1,13]],marker = 'o', c='r', zorder=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-ZCt7Drbm6B","colab_type":"code","colab":{}},"source":["# 1.3 Model training for classification with Fashion-MNIST (Done)\n","import torch\n","import torchvision\n","from torch import nn\n","from torch.nn.functional import cross_entropy\n","from torchvision import transforms, utils\n","from torchvision.transforms import ToTensor\n","import torchvision.datasets as datasets\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","import progressbar\n","import numpy as np\n","from math import ceil\n","import pickle\n","\n","class Network(nn.Module):\n","    def __init__(self, num_classes, input_shape):\n","        super(Network, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(input_shape[0], 6, (5, 5))\n","        self.act1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(2, stride=2)\n","        self.conv2 = nn.Conv2d(6, 12, (5, 5))\n","        self.act2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(2, stride=2)\n","        self.linear1 = nn.Linear(4*4*12, 120)\n","        self.act3 = nn.ReLU()\n","        self.linear2 = nn.Linear(120, 60)\n","        self.act4 = nn.ReLU()\n","        self.linear3 = nn.Linear(60,num_classes)\n","        #last layer should be softmax which is used for multiclass problems\n","        # inputs of softmax are usually normalized\n","        # at the end, cross entropy is used after softmax. Inputs to cross entropy are softmax output and ground-truth\n","\n","    def forward(self, x):\n","        x = self.pool1(self.act1(self.conv1(x)))\n","        x = self.pool2(self.act2(self.conv2(x)))\n","        x = x.view(-1, 4*4*12)\n","        x = self.act3(self.linear1(x))\n","        x = self.act4(self.linear2(x))\n","        x = self.linear3(x)\n","        return x\n","\n","NUM_EPOCHS = 10\n","BATCH_SIZE = 10\n","NUM_CLASSES = 10\n","LR = 0.001\n","\n","def main():\n","  # first we download the dataset here\n","  train_set = datasets.FashionMNIST('.', download=True, train=True, transform=transforms.ToTensor())\n","  test_set = datasets.FashionMNIST('.', download=True, train=False, transform=transforms.ToTensor())\n","  train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle= True)\n","  test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=False)\n","\n","  # instantiate the model\n","  model = Network(NUM_CLASSES, (1, 28, 28))\n","  optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","\n","  train_losses = []\n","  test_losses = []\n","  train_accuracy = [] \n","  test_accuracy = [] \n","  for epoch in range(NUM_EPOCHS):\n","    for mode, data in [(\"train\", train_loader), (\"test\", test_loader)]:\n","  \n","      runningLoss = 0.\n","      correct = 0\n","      total = 0\n","      for step, (images, labels) in enumerate(data):   # looping over each batch data\n","        \n","        predictions = model.forward(images)\n","        correct += (torch.argmax(predictions, dim=-1) == labels).sum() #torch.argmax(predictions, dim=-1) find index of max values along columns in each row\n","        total += images.shape[0]\n","\n","        loss = cross_entropy(predictions, labels)\n","        runningLoss += loss.item() * images.shape[0]\n","        \n","        if mode == \"train\":\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","\n","      (train_losses if mode == \"train\" else test_losses).append(runningLoss / total)\n","      (train_accuracy if mode == \"train\" else test_accuracy).append(float(correct) / total) \n","      print(\"epochs: {} | {} | total correct: {} | total loss: {}\".format(epoch,mode,correct,runningLoss/total))\n","\n","  with open('/content/drive/My Drive/train_test_losses.pickle', \"wb\") as f: # file = 'train_test_losses.pickle'\n","    pickle.dump((train_losses, test_losses), f)\n","\n","  with open('/content/drive/My Drive/train_test_accuracy.pickle', \"wb\") as g: # file = 'train_test_accuracy.pickle'\n","    pickle.dump((train_accuracy, test_accuracy), g)\n","          \n","if __name__ == \"__main__\":\n","    main()\n","\n","######################## Plots #################################################\n","with open(\"/content/drive/My Drive/train_test_losses.pickle\", \"rb\") as f:\n","        train_losses, test_losses = pickle.load(f)\n","\n","with open(\"/content/drive/My Drive/train_test_accuracy.pickle\", \"rb\") as g:\n","        train_accuracy, test_accuracy = pickle.load(g)\n","\n","plt.plot(np.arange(0, len(train_losses)), train_losses, label= \"train loss\", color=\"blue\")\n","plt.plot(np.arange(0, len(train_losses)), test_losses, label= \"test loss\", color=\"green\")\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"loss\")\n","plt.legend()\n","plt.show()\n","\n","plt.plot(np.arange(0, len(train_accuracy)), train_accuracy, label= \"train accuracy\", color=\"blue\")\n","plt.plot(np.arange(0, len(train_accuracy)), test_accuracy, label= \"test accuracy\", color=\"green\")\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"accuracy\")\n","plt.legend()\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hs-xm5cubxVT","colab_type":"code","colab":{}},"source":["# 1.4 Model Training for Regression: LSP (Done)\n","import torch\n","from torch import nn\n","import torchvision\n","from torchvision import transforms, utils\n","import torchvision.datasets as datasets\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","import scipy.io as sio\n","from os.path import dirname, normpath, normcase, join as pjoin\n","import numpy as np\n","import urllib.request\n","from skimage import io\n","import os\n","import math\n","from torch.nn.functional import cross_entropy\n","import pickle\n","\n","class Network(nn.Module):\n","    def __init__(self, input_shape):\n","        super(Network, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(input_shape[0], 6, (5, 5))\n","        self.act1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(2, stride=2)\n","        self.conv2 = nn.Conv2d(6, 12, (5, 5))\n","        self.act2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(2, stride=2)\n","        self.conv3 = nn.Conv2d(12, 12, (5, 5))\n","        self.act3 = nn.ReLU()\n","        self.pool3 = nn.MaxPool2d(2, stride=1)\n","        self.linear1 = nn.Linear(56*56*12, 120)\n","        self.act4 = nn.ReLU()\n","        self.linear2 = nn.Linear(120, 60)\n","        self.act5 = nn.ReLU()\n","        self.linear3 = nn.Linear(60,30) \n","        self.act6 = nn.ReLU()\n","        self.linear4 = nn.Linear(30,28)\n","\n","    def forward(self, x):\n","        x = self.pool1(self.act1(self.conv1(x.float())))\n","        x = self.pool2(self.act2(self.conv2(x)))\n","        x = self.pool3(self.act3(self.conv3(x)))\n","        x = x.view(-1, 56*56*12)\n","        x = self.act4(self.linear1(x))\n","        x = self.act5(self.linear2(x))\n","        x = self.act6(self.linear3(x))\n","        x = self.linear4(x)\n","        return x\n","\n","class CustomLSP(Dataset):\n","  \n","  def __init__(self, data_dir, train_size, train):\n","    joints_dir = pjoin(data_dir, 'joints.mat')\n","    images_folder = pjoin(data_dir, 'images')\n","    #visualized_folder = pjoin(data_dir, 'visualized')\n","    mat_contents = sio.loadmat(joints_dir)\n","    joints = mat_contents['joints']\n","    images = sorted(os.listdir(images_folder)) # sorted list of images\n","    self.train = train\n","\n","    if self.train == True:\n","      self.train_len = train_size * len(images) / 100 # this is train_size * 2000 / 100\n","      self.train_image_set = []\n","      self.train_joint_set = []\n","      for i in range(0,int(self.train_len)):\n","        \n","        # resizing images to equal sizes and modifying joints accordingly\n","        im = plt.imread(pjoin(images_folder,images[i]))\n","        h, w = im.shape[:2]\n","        im = cv2.resize(im, (256, 256)) \n","        im = torch.from_numpy(im)\n","\n","        im = im.view(3,1,256*256).view(3,256,256)\n","\n","        self.train_image_set.append(im)\n","        joints_i = torch.from_numpy(joints[:2,:,i]) # ignoring the visibility term in joints\n","        joints_i[0,:] = torch.mul(joints_i[0,:], 256/w) # modifying joints\n","        joints_i[1,:] = torch.mul(joints_i[1,:], 256/h) # modifying joints\n","        joints_i = torch.reshape(joints_i,(1,28)) # joints reshaped so that later joints and predictions have same shape for loss calculation\n","        self.train_joint_set.append(joints_i)  \n","        \n","    if self.train == False:\n","      self.train_len = train_size * len(images) / 100 # this is train_size * 2000 / 100\n","      self.test_len = (100 - train_size) * len(images) / 100\n","      self.test_image_set = []\n","      self.test_joint_set = []\n","      for i in range(int(self.train_len),len(images)):\n","\n","        # resizing images to equal sizes and modifying joints accordingly\n","        im = plt.imread(pjoin(images_folder,images[i]))\n","        h, w = im.shape[:2]\n","        im = cv2.resize(im, (256, 256)) \n","        im = torch.from_numpy(im)\n","        \n","        im = im.view(3,1,256*256).view(3,256,256)\n","\n","        self.test_image_set.append(im)\n","        joints_i = torch.from_numpy(joints[:2,:,i]) # ignoring the visibility term in joints\n","        joints_i[0,:] = torch.mul(joints_i[0,:], 256/w) # modifying joints\n","        joints_i[1,:] = torch.mul(joints_i[1,:], 256/h) # modifying joints\n","        joints_i = torch.reshape(joints_i,(1,28)) # joints reshaped so that later joints and predictions have same shape for loss calculation\n","        self.test_joint_set.append(joints_i)\n","        \n","  def __getitem__(self, index):\n","    if self.train == True:\n","      train_images = self.train_image_set[index]\n","      train_joints = self.train_joint_set[index]\n","      return train_images, train_joints\n","    if self.train == False:\n","      test_images = self.test_image_set[index]\n","      test_joints = self.test_joint_set[index]\n","      return test_images, test_joints\n","  \n","  def __len__(self):\n","    if self.train == True:\n","      return int(self.train_len)\n","    if self.train == False:\n","      return int(self.test_len)\n","\n","NUM_EPOCHS = 10\n","BATCH_SIZE = 64 # samples in one batch\n","LR = 0.001\n","train_size = 80; # 80% of the data\n","test_size = 100 - train_size; # 20% of the data \n","\n","def main():\n","  data_dir = pjoin('/content/drive/My Drive/lsp_dataset')\n","  train_set = CustomLSP(data_dir, train_size=80, train=True)\n","  test_set = CustomLSP(data_dir, train_size=80, train=False)\n","  train_loader = torch.utils.data.DataLoader(train_set, BATCH_SIZE, shuffle=True)\n","  test_loader = torch.utils.data.DataLoader(test_set, BATCH_SIZE, shuffle=True)\n","\n","  # instantiate the model\n","  model = Network((3,256, 256))\n","  optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","\n","  train_losses = []\n","  test_losses = []\n","  for epoch in range(NUM_EPOCHS):\n","    for mode, data in [(\"train\", train_loader), (\"test\", test_loader)]:\n","  \n","      runningLoss = 0.\n","      correct = 0\n","      total = 0\n","      for step, (images, joints) in enumerate(data):   # looping over each batch data\n","        \n","        predictions = model.forward(images)\n","        total += images.shape[0]\n","\n","        error = joints - predictions\n","        loss = error.pow(2).mean()\n","    \n","        runningLoss += loss.item() * images.shape[0]\n","        \n","        if mode == \"train\":\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","\n","      (train_losses if mode == \"train\" else test_losses).append(runningLoss / total)\n","      print(\"epochs: {} | {} | total loss: {}\".format(epoch,mode,runningLoss/total))\n","\n","\n","  with open('/content/drive/My Drive/LSP_train_test_losses.pickle', \"wb\") as f: # file = 'LSP_train_test_losses.pickle'\n","    pickle.dump((train_losses, test_losses), f)\n","          \n","if __name__ == \"__main__\":\n","    main()\n","\n","######################## Plots #################################################\n","with open(\"/content/drive/My Drive/LSP_train_test_losses.pickle\", \"rb\") as f:\n","        train_losses, test_losses = pickle.load(f)\n","\n","plt.plot(np.arange(0, len(train_losses)), train_losses, label= \"train loss\", color=\"blue\")\n","plt.plot(np.arange(0, len(train_losses)), test_losses, label= \"test loss\", color=\"green\")\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"loss\")\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PaRjYgGUdE6f","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]}]}